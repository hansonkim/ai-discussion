"""AI ëª¨ë¸ ê´€ë¦¬ ì„œë¹„ìŠ¤"""

import subprocess
from typing import Dict
from ai_debate.models.ai_model import AIModel
from ai_debate.io.cache_manager import CacheManager
from ai_debate.config.constants import ALL_AI_MODELS, MODEL_CHECK_TIMEOUT
from ai_debate.exceptions import NoAvailableModelsError


class ModelManager:
    """AI ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ë° ê´€ë¦¬

    Attributes:
        cache_manager: ìºì‹œ ê´€ë¦¬ì
        available_models: ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
    """

    def __init__(self, cache_manager: CacheManager):
        """
        Args:
            cache_manager: ìºì‹œ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
        """
        self.cache_manager = cache_manager
        self.available_models: Dict[str, AIModel] = {}

    def check_model_availability(
        self,
        model_key: str,
        model: AIModel
    ) -> bool:
        """íŠ¹ì • AI ëª¨ë¸ì˜ CLIê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸

        Args:
            model_key: ëª¨ë¸ í‚¤ (ì˜ˆ: "claude")
            model: AI ëª¨ë¸ ì •ë³´

        Returns:
            ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì•„ë‹ˆë©´ False
        """
        test_cmd = model.test_command or model.command[:1] + ["--version"]

        try:
            result = subprocess.run(
                test_cmd,
                capture_output=True,
                text=True,
                timeout=MODEL_CHECK_TIMEOUT,
                encoding='utf-8'
            )
            # ëª…ë ¹ì–´ê°€ ì‹¤í–‰ë˜ê³  ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ ì‚¬ìš© ê°€ëŠ¥
            return result.returncode in [0, 1]
        except FileNotFoundError:
            return False
        except subprocess.TimeoutExpired:
            # íƒ€ì„ì•„ì›ƒì€ ì‹¤í–‰ì€ ë˜ì§€ë§Œ ì‘ë‹µì´ ëŠë¦° ê²½ìš°
            return True
        except Exception:
            return False

    def initialize_models(self, force_refresh: bool = False) -> None:
        """ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ í™•ì¸ ë° ì´ˆê¸°í™”

        Args:
            force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ê°•ì œë¡œ ì¬í™•ì¸

        Raises:
            NoAvailableModelsError: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ì„ ê²½ìš°
        """
        # ìºì‹œ í™•ì¸ (force_refreshê°€ ì•„ë‹ ë•Œë§Œ)
        if not force_refresh:
            cached_keys = self.cache_manager.load_cached_models()
            if cached_keys:
                print("âœ… ìºì‹œëœ AI ëª¨ë¸ ì •ë³´ ì‚¬ìš©")
                self.available_models = {
                    key: ALL_AI_MODELS[key]
                    for key in cached_keys
                    if key in ALL_AI_MODELS
                }
                if self.available_models:
                    model_names = ', '.join(m.display_name for m in self.available_models.values())
                    print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸: {model_names}\n")
                    return
                else:
                    print("âš ï¸  ìºì‹œëœ ëª¨ë¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¬í™•ì¸í•©ë‹ˆë‹¤...\n")

        # AI ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
        print("ğŸ” AI ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì¤‘...")
        print("-" * 60)

        # ì´ˆê¸°í™” (ì´ì „ ë°ì´í„° ì œê±°)
        self.available_models.clear()
        available_keys = []

        for model_key, model in ALL_AI_MODELS.items():
            print(f"  - {model.display_name}...", end=" ", flush=True)

            if self.check_model_availability(model_key, model):
                self.available_models[model_key] = model
                available_keys.append(model_key)
                print("âœ… ì‚¬ìš© ê°€ëŠ¥")
            else:
                print("âŒ ì‚¬ìš© ë¶ˆê°€")

        print("-" * 60)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not self.available_models:
            error_msg = self._get_installation_guide()
            raise NoAvailableModelsError(error_msg)

        # ìºì‹œ ì €ì¥
        self.cache_manager.save_cached_models(available_keys)

        print(f"\nâœ… {len(self.available_models)}ê°œì˜ AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
        model_names = ', '.join(m.display_name for m in self.available_models.values())
        print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {model_names}\n")

    def get_available_models(self) -> Dict[str, AIModel]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë°˜í™˜

        Returns:
            ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
        """
        return self.available_models

    @staticmethod
    def _get_installation_guide() -> str:
        """AI CLI ì„¤ì¹˜ ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„±

        Returns:
            ì„¤ì¹˜ ì•ˆë‚´ ë©”ì‹œì§€
        """
        return """
âŒ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒì˜ AI CLIë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:

1. Claude (Anthropic)
   - ì„¤ì¹˜: npm install -g @anthropic-ai/claude-cli
   - ë¬¸ì„œ: https://docs.anthropic.com/claude/docs/claude-cli

2. OpenAI GPT (Codex)
   - ì„¤ì¹˜: npm install -g @openai/codex-cli
   - ë¬¸ì„œ: https://platform.openai.com/docs/codex

3. Gemini (Google)
   - ì„¤ì¹˜: pip install google-generativeai
   - ë¬¸ì„œ: https://ai.google.dev/docs

4. Grok (xAI)
   - ì„¤ì¹˜: pip install grok-cli
   - ë¬¸ì„œ: https://x.ai/docs

ğŸ’¡ ìºì‹œë¥¼ ê°•ì œë¡œ ê°±ì‹ í•˜ë ¤ë©´ '.ai_models_cache.json' íŒŒì¼ì„ ì‚­ì œí•˜ì„¸ìš”.
"""
