"""AI ëª¨ë¸ ê´€ë¦¬ ì„œë¹„ìŠ¤"""

import subprocess
from typing import Dict
from ai_debate.models.ai_model import AIModel
from ai_debate.io.cache_manager import CacheManager
from ai_debate.config.constants import ALL_AI_MODELS, MODEL_CHECK_TIMEOUT
from ai_debate.exceptions import NoAvailableModelsError


class ModelManager:
    """AI ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ë° ê´€ë¦¬

    Attributes:
        cache_manager: ìºì‹œ ê´€ë¦¬ì
        available_models: ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
    """

    def __init__(self, cache_manager: CacheManager):
        """
        Args:
            cache_manager: ìºì‹œ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
        """
        self.cache_manager = cache_manager
        self.available_models: Dict[str, AIModel] = {}

    def check_model_availability(
        self,
        model_key: str,
        model: AIModel
    ) -> bool:
        """íŠ¹ì • AI ëª¨ë¸ì˜ CLIê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸

        Args:
            model_key: ëª¨ë¸ í‚¤ (ì˜ˆ: "claude")
            model: AI ëª¨ë¸ ì •ë³´

        Returns:
            ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True, ì•„ë‹ˆë©´ False
        """
        # 1ë‹¨ê³„: CLI ì„¤ì¹˜ í™•ì¸ (ë¹ ë¥¸ ì²´í¬)
        test_cmd = model.test_command or model.command[:1] + ["--version"]

        try:
            result = subprocess.run(
                test_cmd,
                capture_output=True,
                text=True,
                timeout=MODEL_CHECK_TIMEOUT * 2,
                encoding='utf-8'
            )
            # CLIê°€ ì—†ê±°ë‚˜ ì‹¬ê°í•œ ì˜¤ë¥˜ë©´ ì¦‰ì‹œ False
            if result.returncode not in [0, 1]:
                return False
        except FileNotFoundError:
            return False
        except subprocess.TimeoutExpired:
            # íƒ€ì„ì•„ì›ƒì€ ì‹¤í–‰ì€ ë˜ì§€ë§Œ ì‘ë‹µì´ ëŠë¦° ê²½ìš°
            pass
        except Exception:
            return False

        # 2ë‹¨ê³„: ì‹¤ì œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ í˜¸ì¶œë¡œ í¬ë ˆë”§/ì¸ì¦ í™•ì¸)
        try:
            test_prompt = "ok"
            result = subprocess.run(
                model.command + [test_prompt],
                capture_output=True,
                text=True,
                timeout=10.0,  # AI API í˜¸ì¶œì€ ì¶©ë¶„í•œ ì‹œê°„ í•„ìš” (10ì´ˆ)
                encoding='utf-8'
            )

            # stdoutê³¼ stderr ëª¨ë‘ì—ì„œ ëª…í™•í•œ ì—ëŸ¬ë§Œ í™•ì¸
            output = (result.stdout + result.stderr).lower()

            # í¬ë ˆë”§/ì¸ì¦ ê´€ë ¨ ëª…í™•í•œ ì—ëŸ¬ í‚¤ì›Œë“œ
            critical_errors = [
                "doesn't have any credits",
                'purchase credits',
                'no credits',
                'credit balance',
                'billing',
                'payment required'
            ]

            # ëª…í™•í•œ í¬ë ˆë”§/ê²°ì œ ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš© ë¶ˆê°€
            if any(error in output for error in critical_errors):
                return False

            # returncode 0ì´ë©´ ì„±ê³µ
            if result.returncode == 0:
                return True

            # ê·¸ ì™¸ì˜ ê²½ìš°ëŠ” CLIê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì‚¬ìš© ê°€ëŠ¥ìœ¼ë¡œ ê°„ì£¼
            # (API í‚¤ ì„¤ì • ë“±ì€ ì‚¬ìš©ìê°€ ì‹¤ì œ ì‚¬ìš© ì‹œ í•´ê²°í•  ë¬¸ì œ)
            return True

        except subprocess.TimeoutExpired:
            # íƒ€ì„ì•„ì›ƒ = APIê°€ ëŠë¦¬ì§€ë§Œ ë™ì‘í•¨ (ì‚¬ìš© ê°€ëŠ¥)
            return True
        except Exception:
            # ê¸°íƒ€ ì—ëŸ¬ëŠ” CLIê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì‚¬ìš© ê°€ëŠ¥ìœ¼ë¡œ ê°„ì£¼
            return True

    def initialize_models(self, force_refresh: bool = False) -> None:
        """ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ í™•ì¸ ë° ì´ˆê¸°í™”

        Args:
            force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ê°•ì œë¡œ ì¬í™•ì¸

        Raises:
            NoAvailableModelsError: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ì„ ê²½ìš°
        """
        # ìºì‹œ í™•ì¸ (force_refreshê°€ ì•„ë‹ ë•Œë§Œ)
        if not force_refresh:
            cached_keys = self.cache_manager.load_cached_models()
            if cached_keys:
                print("âœ… ìºì‹œëœ AI ëª¨ë¸ ì •ë³´ ì‚¬ìš©")
                self.available_models = {
                    key: ALL_AI_MODELS[key]
                    for key in cached_keys
                    if key in ALL_AI_MODELS
                }
                if self.available_models:
                    model_names = ', '.join(m.display_name for m in self.available_models.values())
                    print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸: {model_names}\n")
                    return
                else:
                    print("âš ï¸  ìºì‹œëœ ëª¨ë¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¬í™•ì¸í•©ë‹ˆë‹¤...\n")

        # AI ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
        print("ğŸ” AI ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì¤‘...")
        print("-" * 60)

        # ì´ˆê¸°í™” (ì´ì „ ë°ì´í„° ì œê±°)
        self.available_models.clear()
        available_keys = []

        for model_key, model in ALL_AI_MODELS.items():
            print(f"  - {model.display_name}...", end=" ", flush=True)

            if self.check_model_availability(model_key, model):
                self.available_models[model_key] = model
                available_keys.append(model_key)
                print("âœ… ì‚¬ìš© ê°€ëŠ¥")
            else:
                print("âŒ ì‚¬ìš© ë¶ˆê°€")

        print("-" * 60)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not self.available_models:
            error_msg = self._get_installation_guide()
            raise NoAvailableModelsError(error_msg)

        # ìºì‹œ ì €ì¥
        self.cache_manager.save_cached_models(available_keys)

        print(f"\nâœ… {len(self.available_models)}ê°œì˜ AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
        model_names = ', '.join(m.display_name for m in self.available_models.values())
        print(f"ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {model_names}\n")

    def get_available_models(self) -> Dict[str, AIModel]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë°˜í™˜

        Returns:
            ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
        """
        return self.available_models

    @staticmethod
    def _get_installation_guide() -> str:
        """AI CLI ì„¤ì¹˜ ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„±

        Returns:
            ì„¤ì¹˜ ì•ˆë‚´ ë©”ì‹œì§€
        """
        return """
âŒ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒì˜ AI CLIë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:

1. Claude (Anthropic)
   - ì„¤ì¹˜: npm install -g @anthropic-ai/claude-cli
   - ë¬¸ì„œ: https://docs.anthropic.com/claude/docs/claude-cli

2. OpenAI GPT (Codex)
   - ì„¤ì¹˜: npm install -g @openai/codex-cli
   - ë¬¸ì„œ: https://platform.openai.com/docs/codex

3. Gemini (Google)
   - ì„¤ì¹˜: pip install google-generativeai
   - ë¬¸ì„œ: https://ai.google.dev/docs

4. Grok (xAI)
   - ì„¤ì¹˜: pip install grok-cli
   - ë¬¸ì„œ: https://x.ai/docs

ğŸ’¡ ìºì‹œë¥¼ ê°•ì œë¡œ ê°±ì‹ í•˜ë ¤ë©´ '.ai_models_cache.json' íŒŒì¼ì„ ì‚­ì œí•˜ì„¸ìš”.
"""
